{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An RNN model for temperature data\n",
    "Multi-site model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "import numpy as np\n",
    "import utils_batching\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version: \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "display"
    ]
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import utils_prettystyle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESAMPLE_BY = 5     # averaging period in days (training on daily data is too much)\n",
    "RNN_CELLSIZE = 100  # size of the RNN cells\n",
    "NLAYERS = 2         # number of stacked RNN cells (needed for tensor shapes but code must be changed manually)\n",
    "SEQLEN = 100        # unrolled sequence length\n",
    "BATCHSIZE = 32      # mini-batch size\n",
    "DROPOUT_PKEEP = 0.7 # probability of neurons not being dropped (should be between 0.5 and 1)\n",
    "ACTIVATION = tf.nn.tanh # Activation function for GRU cells (tf.nn.relu or tf.nn.tanh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#32 weather stations\n",
    "weather_stations = ['USC00010655.csv','USC00012813.csv','USC00016478.csv','USC00020949.csv','USC00021314.csv',\n",
    "'USC00025635.csv','USC00026468.csv','USC00029359.csv','USC00030458.csv',\n",
    "'USC00031948.csv','USC00032794.csv','USC00032930.csv','USC00033466.csv','USC00033821.csv','USC00033862.csv',\n",
    "'USC00036920.csv','USC00036928.csv','USC00040343.csv','USC00041244.csv','USC00041428.csv',\n",
    "'USC00042598.csv','USC00042713.csv','USC00042934.csv','USC00043551.csv','USC00043875.csv','USC00044957.csv',\n",
    "'USC00045118.csv','USC00046074.csv','USC00046136.csv','USC00046730.csv','USC00047150.csv','USC00047916.csv']\n",
    "\n",
    "# possible evaluation files: temperatures/USC00040343.csv\"\n",
    "with tf.gfile.Open(\"gs://ml1-demo-martin/good_temperature_data/USC00040343.csv\", mode='rb') as f:\n",
    "    eval_temperatures = np.genfromtxt(f, delimiter=\",\", skip_header=True,\n",
    "                      usecols=[0,1,2,3], converters = {0: lambda s: np.datetime64(s)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "display"
    ]
   },
   "outputs": [],
   "source": [
    "# You can adjust the visualisation range here\n",
    "# Interpolated regions of the dataset are marked in red\n",
    "visu_temperatures = eval_temperatures[:]\n",
    "\n",
    "# when reading from CSV, numpy names its columns f0, f1, f2, ...\n",
    "dates = visu_temperatures[:]['f0']\n",
    "min_temps = visu_temperatures[:]['f1']\n",
    "max_temps = visu_temperatures[:]['f2']\n",
    "interpolated = visu_temperatures[:]['f3']\n",
    "\n",
    "interpolated_sequence = False\n",
    "#plt.plot(dates, max_temps)\n",
    "for i, date in enumerate(dates):\n",
    "    if interpolated[i]:\n",
    "        if not interpolated_sequence:\n",
    "            startdate = date\n",
    "        interpolated_sequence = True\n",
    "        stopdate=date\n",
    "    else:\n",
    "        if interpolated_sequence:\n",
    "            # light shade of red just for visibility\n",
    "            plt.axvspan(startdate+np.timedelta64(-5, 'D'), stopdate+np.timedelta64(6, 'D'), facecolor='#FFCCCC', alpha=1)\n",
    "            # actual interpolated region\n",
    "            plt.axvspan(startdate+np.timedelta64(-1, 'D'), stopdate+np.timedelta64(1, 'D'), facecolor='#FF8888', alpha=1)\n",
    "        interpolated_sequence = False\n",
    "plt.fill_between(dates, min_temps, max_temps).set_zorder(10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dataset we will be working with\n",
    "evaldata = eval_temperatures[:]['f2'] # max temperatures\n",
    "rounded_data_len = evaldata.shape[0]//RESAMPLE_BY*RESAMPLE_BY\n",
    "evaldata = np.reshape(evaldata[:rounded_data_len], [-1, RESAMPLE_BY])\n",
    "evaldata = np.mean(evaldata, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "display"
    ]
   },
   "outputs": [],
   "source": [
    "plt.plot(evaldata[:365*5//RESAMPLE_BY]) # display five years worth of data\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = []\n",
    "for station_i in range(BATCHSIZE):\n",
    "    with tf.gfile.Open(\"gs://ml1-demo-martin/good_temperature_data/\"+weather_stations[station_i], mode='rb') as f:\n",
    "        temperatures = np.genfromtxt(f, delimiter=\",\",\n",
    "                                     skip_header=True,\n",
    "                                     usecols=[0,1,2,3],\n",
    "                                     converters = {0: lambda s: np.datetime64(s)})\n",
    "        temperatures = temperatures[:]['f2'] # max temperatures\n",
    "        traindata.append(temperatures)\n",
    "data = np.stack(traindata, axis=0)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize training sequences\n",
    "This is what the neural network will see during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "display"
    ]
   },
   "outputs": [],
   "source": [
    "# The function rnn_sampling_sequencer puts one weather station per line in a batch\n",
    "# and continues with data from the same station in corresponding lines in the next batch.\n",
    "subplot = 231\n",
    "for samples, labels, epoch in utils_batching.rnn_sampling_sequencer(data, RESAMPLE_BY, SEQLEN, nb_epochs=1):\n",
    "    plt.subplot(subplot)\n",
    "    plt.plot(samples[0,:])\n",
    "    subplot += 1\n",
    "    if subplot==237: break\n",
    "print(\"Sample shape: \" + str(samples.shape))\n",
    "print(\"Label shape: \" + str(labels.shape))\n",
    "print(\"First samples:\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model definition\n",
    "When executed, this function instantiates the Tensorflow graph for our model.\n",
    "![deep RNN schematic](images/deep_rnn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_rnn_fn(features, Hin, labels, dropout_pkeep):\n",
    "    X = features\n",
    "    batchsize = tf.shape(X)[0]\n",
    "    seqlen = tf.shape(X)[1]\n",
    "    \n",
    "    cells = [tf.nn.rnn_cell.GRUCell(RNN_CELLSIZE, activation=ACTIVATION) for _ in range(NLAYERS)]\n",
    "    # dropout useful between cell layers only: no output dropout on last cell\n",
    "    dcells = [tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob = dropout_pkeep) for cell in cells[:-1]]\n",
    "    dcells.append(cells[-1])\n",
    "    # a stacked RNN cell still works like an RNN cell\n",
    "    cell = tf.nn.rnn_cell.MultiRNNCell(dcells, state_is_tuple=False)\n",
    "    # X[BATCHSIZE, SEQLEN, 1], Hin[BATCHSIZE, RNN_CELLSIZE*NLAYERS]\n",
    "    # the sequence unrolling happens here\n",
    "    Yn, H = tf.nn.dynamic_rnn(cell, X, initial_state=Hin, dtype=tf.float32)\n",
    "    # Yn[BATCHSIZE, SEQLEN, RNN_CELLSIZE]\n",
    "    Yn = tf.reshape(Yn, [batchsize*seqlen, RNN_CELLSIZE])\n",
    "    Yr = tf.layers.dense(Yn, 1) # Yr [BATCHSIZE*SEQLEN, 1]\n",
    "    Yr = tf.reshape(Yr, [batchsize, seqlen, 1]) # Yr [BATCHSIZE, SEQLEN, 1]\n",
    "    Yout = Yr[:,-1,:] # Last output Yout [BATCHSIZE, 1]\n",
    "    \n",
    "    loss = tf.losses.mean_squared_error(Yr, labels) # labels[BATCHSIZE, SEQLEN, 1]\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "    train_op = optimizer.minimize(loss)\n",
    "    \n",
    "    return Yout, H, loss, train_op, Yr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder for inputs\n",
    "Hin = tf.placeholder(tf.float32, [None, RNN_CELLSIZE * NLAYERS])\n",
    "samples = tf.placeholder(tf.float32, [None, None, 1]) # [BATCHSIZE, SEQLEN, 1]\n",
    "labels = tf.placeholder(tf.float32, [None, None, 1]) # [BATCHSIZE, SEQLEN, 1]\n",
    "dropout_pkeep = tf.placeholder(tf.float32)\n",
    "\n",
    "# instantiate the model\n",
    "Yout, H, loss, train_op, Yr = model_rnn_fn(samples, Hin, labels, dropout_pkeep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "This is a generative model: run one trained RNN cell in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_run(prime_data, run_length):\n",
    "    H_ = np.zeros([1, RNN_CELLSIZE * NLAYERS]) # zero state initially\n",
    "    Yout_ = np.zeros([1, 1])\n",
    "    data_len = prime_data.shape[0]\n",
    "\n",
    "    # prime the state from data\n",
    "    if data_len > 0:\n",
    "        Yin = np.array(prime_data)\n",
    "        Yin = np.reshape(Yin, [1, data_len, 1]) # reshape as one sequence\n",
    "        feed = {Hin: H_, samples: Yin, dropout_pkeep: 1.0} # no dropout during inference\n",
    "        Yout_, H_ = sess.run([Yout, H], feed_dict=feed)\n",
    "    \n",
    "    # run prediction\n",
    "    # To generate a sequence, run a trained cell in a loop passing as input and input state\n",
    "    # respectively the output and output state from the previous iteration.\n",
    "    results = []\n",
    "    for i in range(run_length):\n",
    "        Yout_ = np.reshape(Yout_, [1, 1, 1]) # batch of a single sequence of a single vector with one element\n",
    "        feed = {Hin: H_, samples: Yout_, dropout_pkeep: 1.0} # no dropout during inference\n",
    "        Yout_, H_ = sess.run([Yout, H], feed_dict=feed)\n",
    "        results.append(Yout_[0,0])\n",
    "        \n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Tensorflow session\n",
    "This resets all neuron weights and biases to initial random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first input state\n",
    "Hzero = np.zeros([BATCHSIZE, RNN_CELLSIZE * NLAYERS])\n",
    "# variable initialization\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run([init])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The training loop\n",
    "You can re-execute this cell to continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_EPOCHS = 300\n",
    "\n",
    "H_ = Hzero\n",
    "losses = []\n",
    "indices = []\n",
    "last_epoch = 0\n",
    "for i, (next_samples, next_labels, epoch) in enumerate(utils_batching.rnn_sampling_sequencer(data, RESAMPLE_BY, SEQLEN, nb_epochs=NB_EPOCHS)):\n",
    "    next_samples = np.expand_dims(next_samples, axis=2) # model wants 3D inputs [BATCHSIZE, SEQLEN, 1] \n",
    "    next_labels = np.expand_dims(next_labels, axis=2)\n",
    "    \n",
    "    # reinintialize state between epochs\n",
    "    #if epoch != last_epoch:\n",
    "    #    H_ = Hzero\n",
    "\n",
    "    feed = {Hin: H_, samples: next_samples, labels: next_labels, dropout_pkeep: DROPOUT_PKEEP}\n",
    "    Yout_, H_, loss_, _, Yr_ = sess.run([Yout, H, loss, train_op, Yr], feed_dict=feed)\n",
    "    last_epoch = epoch\n",
    "    \n",
    "    # print progress\n",
    "    if i%30 == 0:\n",
    "        print(\"epoch \" + str(epoch) + \", batch \" + str(i) + \", loss=\" + str(np.mean(loss_)))\n",
    "        sys.stdout.flush()\n",
    "    if i%10 == 0:\n",
    "        losses.append(np.mean(loss_))\n",
    "        indices.append(i)\n",
    "# This visualisation can be helpful to see how the model \"locks\" on the shape of the curve\n",
    "#    if i%100 == 0:\n",
    "#        plt.figure(figsize=(10,2))\n",
    "#        plt.plot(next_labels[0,:,0])\n",
    "#        plt.plot(Yr_[0,:,0])\n",
    "#        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "display"
    ]
   },
   "outputs": [],
   "source": [
    "plt.ylim(ymax=np.amax(losses[1:])) # ignore first value for scaling\n",
    "plt.plot(indices, losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evaldata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRIMELEN=1000\n",
    "RUNLEN=500\n",
    "OFFSET=300\n",
    "RMSELEN=128\n",
    "prime_data = evaldata[OFFSET:OFFSET+PRIMELEN]\n",
    "results = prediction_run(prime_data, RUNLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "display"
    ]
   },
   "outputs": [],
   "source": [
    "disp_data = evaldata[OFFSET:OFFSET+PRIMELEN+RUNLEN]\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "plt.subplot(211)\n",
    "plt.text(PRIMELEN,2.5,\"DATA |\", color=colors[1], horizontalalignment=\"right\")\n",
    "plt.text(PRIMELEN,2.5,\"| PREDICTED\", color=colors[0], horizontalalignment=\"left\")\n",
    "displayresults = np.ma.array(np.concatenate((np.zeros([PRIMELEN]), results)))\n",
    "displayresults = np.ma.masked_where(displayresults == 0, displayresults)\n",
    "plt.plot(displayresults)\n",
    "displaydata = np.ma.array(np.concatenate((prime_data, np.zeros([RUNLEN]))))\n",
    "displaydata = np.ma.masked_where(displaydata == 0, displaydata)\n",
    "plt.plot(displaydata)\n",
    "plt.subplot(212)\n",
    "plt.text(PRIMELEN,2.5,\"DATA |\", color=colors[1], horizontalalignment=\"right\")\n",
    "plt.text(PRIMELEN,2.5,\"| +PREDICTED\", color=colors[0], horizontalalignment=\"left\")\n",
    "plt.plot(displayresults)\n",
    "plt.plot(disp_data)\n",
    "plt.axvspan(PRIMELEN, PRIMELEN+RMSELEN, color='grey', alpha=0.1, ymin=0.05, ymax=0.95)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = math.sqrt(np.mean((evaldata[OFFSET+PRIMELEN:OFFSET+PRIMELEN+RMSELEN] - results[:RMSELEN])**2))\n",
    "print(\"RMSE on {} predictions (shaded area): {}\".format(RMSELEN, rmse))\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "[http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
